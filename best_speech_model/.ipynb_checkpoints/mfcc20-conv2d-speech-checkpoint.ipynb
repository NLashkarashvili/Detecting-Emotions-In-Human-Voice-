{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os, json, math\n",
    "import scipy.io.wavfile as wavf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, MaxPooling2D, Activation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "sample_r = 22050\n",
    "seconds = 4.3\n",
    "n_samples = int(sample_r * seconds)\n",
    "num_mfcc = 20\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "num_segments = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train/Val/Test -> 20/2/2 (number of actors and actresses)\n",
    "* Speech Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load speech data\n",
    "data = pd.read_csv('../input/ravdess-data/RAVDESS.csv')\n",
    "data_speech = data[data['type']=='speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>actor</th>\n",
       "      <th>male</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  actor   male  \\\n",
       "0           0      2  False   \n",
       "1           0      2  False   \n",
       "2           0      2  False   \n",
       "3           0      2  False   \n",
       "4           0      2  False   \n",
       "\n",
       "                                         folder_name      label  \n",
       "0  ../input/ravdess-speech-song/aaudio_Speech_Act...  surprised  \n",
       "1  ../input/ravdess-speech-song/aaudio_Speech_Act...    neutral  \n",
       "2  ../input/ravdess-speech-song/aaudio_Speech_Act...    disgust  \n",
       "3  ../input/ravdess-speech-song/aaudio_Speech_Act...    disgust  \n",
       "4  ../input/ravdess-speech-song/aaudio_Speech_Act...    neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech['male'] = data_speech['male'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>male</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Speech_Act...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor  male                                        folder_name  label\n",
       "0      2     0  ../input/ravdess-speech-song/aaudio_Speech_Act...      7\n",
       "1      2     0  ../input/ravdess-speech-song/aaudio_Speech_Act...      5\n",
       "2      2     0  ../input/ravdess-speech-song/aaudio_Speech_Act...      2\n",
       "3      2     0  ../input/ravdess-speech-song/aaudio_Speech_Act...      2\n",
       "4      2     0  ../input/ravdess-speech-song/aaudio_Speech_Act...      5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_speech['label'].unique())\n",
    "data_speech['label'] = label_encoder.transform(data_speech['label'])\n",
    "data_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speech = data_speech[data_speech['actor']<=20]\n",
    "val_speech = data_speech[(data_speech['actor']>20) & (data_speech['actor']<=22)]\n",
    "test_speech = data_speech[data_speech['actor']>22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = train_speech['folder_name'].values\n",
    "train_labels = train_speech['label'].values\n",
    "test_folders = test_speech['folder_name'].values\n",
    "test_labels = test_speech['label'].values\n",
    "val_folders = val_speech['folder_name'].values\n",
    "val_labels = val_speech['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mfcc(filenames, labels, num_mfcc=num_mfcc, n_fft=n_fft, \n",
    "                  hop_length=hop_length, num_segments=num_segments):\n",
    "    #save file\n",
    "    data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(n_samples / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(n_samples / hop_length)\n",
    "    for i, (filename, label) in tqdm(enumerate(zip(filenames, labels))):\n",
    "        #load audio file       \n",
    "        signal, sample_rate = librosa.load(filename, sr=sample_r)\n",
    "        signal, _ = librosa.effects.trim(signal, top_db = 30)\n",
    "        if signal.shape[0] < n_samples:\n",
    "            signal = np.pad(signal, n_samples - signal.shape[0])\n",
    "        if signal.shape[0] > n_samples:\n",
    "            signal = signal[:n_samples]\n",
    "        # process segments\n",
    "        for segment in range(num_segments):\n",
    "            # calculate start and finish of the sample\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            # extract mfcc\n",
    "            mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "            mfcc = mfcc.T\n",
    "            #store mfccs and labels\n",
    "            if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                data[\"mfcc\"].append(mfcc.tolist())\n",
    "                data[\"labels\"].append(label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [05:18,  3.77it/s]\n",
      "120it [00:32,  3.68it/s]\n",
      "120it [00:32,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_speech_mfcc = generate_mfcc(filenames=train_folders, labels=train_labels)\n",
    "val_speech_mfcc = generate_mfcc(filenames=val_folders, labels=val_labels)\n",
    "test_speech_mfcc = generate_mfcc(filenames=test_folders, labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = train_speech_mfcc['mfcc'], val_speech_mfcc['mfcc'], test_speech_mfcc['mfcc']\n",
    "X_train, X_valid, X_test = np.array(X_train), np.array(X_valid), np.array(X_test)\n",
    "Y_train, Y_valid, Y_test = train_speech_mfcc['labels'], val_speech_mfcc['labels'], test_speech_mfcc['labels']\n",
    "Y_train, Y_valid, Y_test = np.array(Y_train), np.array(Y_valid), np.array(Y_test)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#8 classes\n",
    "model = tf.keras.Sequential(name='Model-Speech-NMFCC{num_mfcc}'.format(num_mfcc=num_mfcc))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_val_loss = \"convolution_models_n_mfcc{num_mfcc:04d}-val-loss\".format(num_mfcc=num_mfcc)\n",
    "checkpoint_path_loss = model_path_val_loss + \"-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir_loss = os.path.dirname(checkpoint_path_loss)\n",
    "!mkdir $model_path_val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path_loss.format(epoch=0))\n",
    "\n",
    "checkpoint_loss = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_loss, monitor='val_loss', verbose=1,\n",
    "        save_weights_only=True, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model-Speech-NMFCC20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 186, 20, 256)      2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 186, 20, 256)      1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 186, 20, 256)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 93, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 93, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 93, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 93, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 46, 5, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 46, 5, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 5, 128)        295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 46, 5, 128)        512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 23, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 2, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 11, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 11272     \n",
      "=================================================================\n",
      "Total params: 1,049,608\n",
      "Trainable params: 1,048,072\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 6s 53ms/step - loss: 2.0787 - accuracy: 0.2058 - val_loss: 6.2153 - val_accuracy: 0.1333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.21530, saving model to convolution_models_n_mfcc0020-val-loss-0001.ckpt\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.6291 - accuracy: 0.3565 - val_loss: 5.3504 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.21530 to 5.35043, saving model to convolution_models_n_mfcc0020-val-loss-0002.ckpt\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.5905 - accuracy: 0.3762 - val_loss: 4.0856 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.35043 to 4.08565, saving model to convolution_models_n_mfcc0020-val-loss-0003.ckpt\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.4923 - accuracy: 0.4108 - val_loss: 2.8250 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.08565 to 2.82497, saving model to convolution_models_n_mfcc0020-val-loss-0004.ckpt\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.3959 - accuracy: 0.4825 - val_loss: 3.0520 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.82497\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.3316 - accuracy: 0.5118 - val_loss: 1.3586 - val_accuracy: 0.5167\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.82497 to 1.35863, saving model to convolution_models_n_mfcc0020-val-loss-0006.ckpt\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.2189 - accuracy: 0.5617 - val_loss: 1.5518 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.35863\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.1959 - accuracy: 0.5515 - val_loss: 1.4614 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.35863\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.1333 - accuracy: 0.5982 - val_loss: 1.6510 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.35863\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 1.0709 - accuracy: 0.6038 - val_loss: 1.7374 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.35863\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 1.0841 - accuracy: 0.6021 - val_loss: 1.4894 - val_accuracy: 0.4083\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.35863\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.9496 - accuracy: 0.6600 - val_loss: 1.4851 - val_accuracy: 0.4583\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.35863\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.9327 - accuracy: 0.6744 - val_loss: 1.4263 - val_accuracy: 0.3917\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.35863\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.8622 - accuracy: 0.6930 - val_loss: 1.6109 - val_accuracy: 0.4083\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.35863\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.7349 - accuracy: 0.7492 - val_loss: 1.5157 - val_accuracy: 0.4917\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.35863\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.7366 - accuracy: 0.7412 - val_loss: 1.2807 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.35863 to 1.28066, saving model to convolution_models_n_mfcc0020-val-loss-0016.ckpt\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6556 - accuracy: 0.7642 - val_loss: 1.6736 - val_accuracy: 0.4833\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.28066\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.6421 - accuracy: 0.7773 - val_loss: 1.5855 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.28066\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.5494 - accuracy: 0.8265 - val_loss: 1.6141 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.28066\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.5924 - accuracy: 0.7795 - val_loss: 1.4154 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.28066\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.4805 - accuracy: 0.8353 - val_loss: 1.5019 - val_accuracy: 0.4417\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.28066\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.4398 - accuracy: 0.8578 - val_loss: 1.2756 - val_accuracy: 0.4417\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.28066 to 1.27556, saving model to convolution_models_n_mfcc0020-val-loss-0022.ckpt\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.4318 - accuracy: 0.8663 - val_loss: 1.2850 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.27556\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.3407 - accuracy: 0.9038 - val_loss: 1.7070 - val_accuracy: 0.4250\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.27556\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.3237 - accuracy: 0.9042 - val_loss: 1.3520 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.27556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.2758 - accuracy: 0.9221 - val_loss: 1.4874 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.27556\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.2846 - accuracy: 0.9208 - val_loss: 1.3570 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.27556\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.2355 - accuracy: 0.9409 - val_loss: 1.3663 - val_accuracy: 0.5083\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.27556\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.2123 - accuracy: 0.9556 - val_loss: 1.6838 - val_accuracy: 0.4417\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.27556\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.2011 - accuracy: 0.9543 - val_loss: 1.5212 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.27556\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1727 - accuracy: 0.9576 - val_loss: 1.2509 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.27556 to 1.25090, saving model to convolution_models_n_mfcc0020-val-loss-0031.ckpt\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1809 - accuracy: 0.9506 - val_loss: 1.6248 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.25090\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1499 - accuracy: 0.9664 - val_loss: 1.3414 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.25090\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1184 - accuracy: 0.9705 - val_loss: 1.3655 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.25090\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1296 - accuracy: 0.9669 - val_loss: 1.5165 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.25090\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.1081 - accuracy: 0.9822 - val_loss: 1.6842 - val_accuracy: 0.4833\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.25090\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0852 - accuracy: 0.9872 - val_loss: 1.5600 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.25090\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0936 - accuracy: 0.9750 - val_loss: 1.7722 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.25090\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0899 - accuracy: 0.9833 - val_loss: 1.5615 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.25090\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0693 - accuracy: 0.9892 - val_loss: 1.3728 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.25090\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0618 - accuracy: 0.9919 - val_loss: 1.4148 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.25090\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0668 - accuracy: 0.9891 - val_loss: 1.4687 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.25090\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0534 - accuracy: 0.9924 - val_loss: 1.5366 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.25090\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0500 - accuracy: 0.9877 - val_loss: 1.3377 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.25090\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0612 - accuracy: 0.9873 - val_loss: 1.8018 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.25090\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0464 - accuracy: 0.9920 - val_loss: 1.4482 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.25090\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0532 - accuracy: 0.9899 - val_loss: 1.2120 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.25090 to 1.21205, saving model to convolution_models_n_mfcc0020-val-loss-0047.ckpt\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0439 - accuracy: 0.9903 - val_loss: 1.4930 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.21205\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0348 - accuracy: 0.9992 - val_loss: 1.6597 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.21205\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0363 - accuracy: 0.9950 - val_loss: 1.5497 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.21205\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0327 - accuracy: 0.9979 - val_loss: 1.4932 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.21205\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0330 - accuracy: 0.9956 - val_loss: 1.3242 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.21205\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0223 - accuracy: 0.9988 - val_loss: 1.4106 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.21205\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0252 - accuracy: 0.9979 - val_loss: 1.3330 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.21205\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0186 - accuracy: 0.9995 - val_loss: 1.2965 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.21205\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 1.5552 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.21205\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 1.5016 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.21205\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0212 - accuracy: 0.9992 - val_loss: 1.3644 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.21205\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.21205\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 1.3789 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.21205\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0240 - accuracy: 0.9968 - val_loss: 1.7763 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.21205\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0256 - accuracy: 0.9972 - val_loss: 1.2391 - val_accuracy: 0.6917\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.21205\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0183 - accuracy: 0.9985 - val_loss: 1.3579 - val_accuracy: 0.6417\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.21205\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 1.3159 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.21205\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0225 - accuracy: 0.9966 - val_loss: 1.2371 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.21205\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0358 - accuracy: 0.9945 - val_loss: 1.4031 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.21205\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0274 - accuracy: 0.9947 - val_loss: 1.3715 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.21205\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 1.6672 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.21205\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0287 - accuracy: 0.9976 - val_loss: 1.3369 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.21205\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 1.5601 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.21205\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.3652 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.21205\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 1.4526 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.21205\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.21205\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 1.3369 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.21205\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0165 - accuracy: 0.9993 - val_loss: 1.4842 - val_accuracy: 0.6417\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.21205\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 1.4408 - val_accuracy: 0.5583\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.21205\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 2.3182 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.21205\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0533 - accuracy: 0.9852 - val_loss: 2.0380 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.21205\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 2.5869 - val_accuracy: 0.4917\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.21205\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0516 - accuracy: 0.9879 - val_loss: 1.2647 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.21205\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0524 - accuracy: 0.9913 - val_loss: 1.5408 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss did not improve from 1.21205\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0530 - accuracy: 0.9861 - val_loss: 1.3364 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.21205\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 1.6023 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.21205\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0329 - accuracy: 0.9862 - val_loss: 1.1716 - val_accuracy: 0.6583\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.21205 to 1.17156, saving model to convolution_models_n_mfcc0020-val-loss-0084.ckpt\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0291 - accuracy: 0.9952 - val_loss: 1.5001 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.17156\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 1.4154 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.17156\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 1.4645 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.17156\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0370 - accuracy: 0.9943 - val_loss: 1.8395 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.17156\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 1.7615 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.17156\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 1.6247 - val_accuracy: 0.6417\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.17156\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 1.6911 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.17156\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 1.6872 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.17156\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.3608 - val_accuracy: 0.6083\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.17156\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6001 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.17156\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3042 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.17156\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 1.4812 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.17156\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.5418 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.17156\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.5100 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.17156\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 1.5449 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.17156\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.17156\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), \n",
    "                    batch_size=32, epochs=100, callbacks=[checkpoint_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2843 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with best val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4c0c0d0290>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir_loss)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1798 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
