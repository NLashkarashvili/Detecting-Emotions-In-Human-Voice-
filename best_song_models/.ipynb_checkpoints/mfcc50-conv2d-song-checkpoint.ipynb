{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os, json, math\n",
    "import scipy.io.wavfile as wavf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, MaxPooling2D, Activation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "sample_r = 22050\n",
    "seconds = 4.3\n",
    "n_samples = int(sample_r * seconds)\n",
    "num_mfcc = 50\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "num_segments = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train/Val/Test -> 20/2/2 (number of actors and actresses)\n",
    "* Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load speech data\n",
    "data = pd.read_csv('../input/ravdess-data/RAVDESS.csv')\n",
    "data_speech = data[data['type']=='song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>actor</th>\n",
       "      <th>male</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  actor   male  \\\n",
       "1440           0      2  False   \n",
       "1441           0      2  False   \n",
       "1442           0      2  False   \n",
       "1443           0      2  False   \n",
       "1444           0      2  False   \n",
       "\n",
       "                                            folder_name    label  \n",
       "1440  ../input/ravdess-speech-song/aaudio_Song_Actor...    angry  \n",
       "1441  ../input/ravdess-speech-song/aaudio_Song_Actor...  fearful  \n",
       "1442  ../input/ravdess-speech-song/aaudio_Song_Actor...    happy  \n",
       "1443  ../input/ravdess-speech-song/aaudio_Song_Actor...    happy  \n",
       "1444  ../input/ravdess-speech-song/aaudio_Song_Actor...      sad  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech['male'] = data_speech['male'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>male</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ravdess-speech-song/aaudio_Song_Actor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actor  male                                        folder_name  label\n",
       "1440      2     0  ../input/ravdess-speech-song/aaudio_Song_Actor...      0\n",
       "1441      2     0  ../input/ravdess-speech-song/aaudio_Song_Actor...      2\n",
       "1442      2     0  ../input/ravdess-speech-song/aaudio_Song_Actor...      3\n",
       "1443      2     0  ../input/ravdess-speech-song/aaudio_Song_Actor...      3\n",
       "1444      2     0  ../input/ravdess-speech-song/aaudio_Song_Actor...      5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_speech['label'].unique())\n",
    "data_speech['label'] = label_encoder.transform(data_speech['label'])\n",
    "data_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speech = data_speech[data_speech['actor']<=20]\n",
    "val_speech = data_speech[(data_speech['actor']>20) & (data_speech['actor']<=22)]\n",
    "test_speech = data_speech[data_speech['actor']>22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = train_speech['folder_name'].values\n",
    "train_labels = train_speech['label'].values\n",
    "test_folders = test_speech['folder_name'].values\n",
    "test_labels = test_speech['label'].values\n",
    "val_folders = val_speech['folder_name'].values\n",
    "val_labels = val_speech['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mfcc(filenames, labels, num_mfcc=num_mfcc, n_fft=n_fft, \n",
    "                  hop_length=hop_length, num_segments=num_segments):\n",
    "    #save file\n",
    "    data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(n_samples / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(n_samples / hop_length)\n",
    "    for i, (filename, label) in tqdm(enumerate(zip(filenames, labels))):\n",
    "        #load audio file       \n",
    "        signal, sample_rate = librosa.load(filename, sr=sample_r)\n",
    "        signal, _ = librosa.effects.trim(signal, top_db = 30)\n",
    "        if signal.shape[0] < n_samples:\n",
    "            signal = np.pad(signal, n_samples - signal.shape[0])\n",
    "        if signal.shape[0] > n_samples:\n",
    "            signal = signal[:n_samples]\n",
    "        # process segments\n",
    "        for segment in range(num_segments):\n",
    "            # calculate start and finish of the sample\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            # extract mfcc\n",
    "            mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "            mfcc = mfcc.T\n",
    "            #store mfccs and labels\n",
    "            if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                data[\"mfcc\"].append(mfcc.tolist())\n",
    "                data[\"labels\"].append(label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "836it [03:46,  3.70it/s]\n",
      "88it [00:24,  3.59it/s]\n",
      "88it [00:24,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_speech_mfcc = generate_mfcc(filenames=train_folders, labels=train_labels)\n",
    "val_speech_mfcc = generate_mfcc(filenames=val_folders, labels=val_labels)\n",
    "test_speech_mfcc = generate_mfcc(filenames=test_folders, labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = train_speech_mfcc['mfcc'], val_speech_mfcc['mfcc'], test_speech_mfcc['mfcc']\n",
    "X_train, X_valid, X_test = np.array(X_train), np.array(X_valid), np.array(X_test)\n",
    "Y_train, Y_valid, Y_test = train_speech_mfcc['labels'], val_speech_mfcc['labels'], test_speech_mfcc['labels']\n",
    "Y_train, Y_valid, Y_test = np.array(Y_train), np.array(Y_valid), np.array(Y_test)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#8 classes\n",
    "model = tf.keras.Sequential(name='Model-Speech-NMFCC{num_mfcc}'.format(num_mfcc=num_mfcc))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', strides = (1, 1),  \\\n",
    "                use_bias = True, activation = 'relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_val_loss = \"convolution_models_n_mfcc{num_mfcc:04d}-val-loss\".format(num_mfcc=num_mfcc)\n",
    "checkpoint_path_loss = model_path_val_loss + \"-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir_loss = os.path.dirname(checkpoint_path_loss)\n",
    "!mkdir $model_path_val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path_loss.format(epoch=0))\n",
    "\n",
    "checkpoint_loss = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_loss, monitor='val_loss', verbose=1,\n",
    "        save_weights_only=True, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model-Speech-NMFCC50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 186, 50, 256)      2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 186, 50, 256)      1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 186, 50, 256)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 93, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 93, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 93, 25, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 93, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 46, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 46, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 12, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 46, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 23, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 6, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 11, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4224)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 25350     \n",
      "=================================================================\n",
      "Total params: 1,063,686\n",
      "Trainable params: 1,062,150\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 6s 84ms/step - loss: 2.2440 - accuracy: 0.2590 - val_loss: 7.5817 - val_accuracy: 0.1818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.58171, saving model to convolution_models_n_mfcc0050-val-loss-0001.ckpt\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 1.3584 - accuracy: 0.4420 - val_loss: 6.8104 - val_accuracy: 0.1818\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.58171 to 6.81042, saving model to convolution_models_n_mfcc0050-val-loss-0002.ckpt\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 1.0843 - accuracy: 0.5625 - val_loss: 6.1683 - val_accuracy: 0.1818\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.81042 to 6.16828, saving model to convolution_models_n_mfcc0050-val-loss-0003.ckpt\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.8322 - accuracy: 0.6865 - val_loss: 5.3338 - val_accuracy: 0.3182\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.16828 to 5.33379, saving model to convolution_models_n_mfcc0050-val-loss-0004.ckpt\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.6401 - accuracy: 0.7410 - val_loss: 2.7273 - val_accuracy: 0.4205\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.33379 to 2.72731, saving model to convolution_models_n_mfcc0050-val-loss-0005.ckpt\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.5565 - accuracy: 0.7978 - val_loss: 2.8591 - val_accuracy: 0.4205\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.72731\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.4404 - accuracy: 0.8332 - val_loss: 1.5107 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.72731 to 1.51073, saving model to convolution_models_n_mfcc0050-val-loss-0007.ckpt\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.3726 - accuracy: 0.8361 - val_loss: 0.6165 - val_accuracy: 0.7386\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.51073 to 0.61653, saving model to convolution_models_n_mfcc0050-val-loss-0008.ckpt\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.3896 - accuracy: 0.8537 - val_loss: 0.9402 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61653\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.3668 - accuracy: 0.8553 - val_loss: 0.5929 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61653 to 0.59289, saving model to convolution_models_n_mfcc0050-val-loss-0010.ckpt\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2843 - accuracy: 0.8827 - val_loss: 0.5805 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59289 to 0.58049, saving model to convolution_models_n_mfcc0050-val-loss-0011.ckpt\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2611 - accuracy: 0.8795 - val_loss: 0.6448 - val_accuracy: 0.7273\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.58049\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2284 - accuracy: 0.9065 - val_loss: 0.9355 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.58049\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.4161 - accuracy: 0.8392 - val_loss: 1.9317 - val_accuracy: 0.5682\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.58049\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2982 - accuracy: 0.8670 - val_loss: 0.5052 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58049 to 0.50519, saving model to convolution_models_n_mfcc0050-val-loss-0015.ckpt\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1948 - accuracy: 0.9242 - val_loss: 0.5049 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50519 to 0.50485, saving model to convolution_models_n_mfcc0050-val-loss-0016.ckpt\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.1929 - accuracy: 0.9304 - val_loss: 1.1374 - val_accuracy: 0.6932\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50485\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1782 - accuracy: 0.9292 - val_loss: 0.5990 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50485\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1359 - accuracy: 0.9482 - val_loss: 1.3357 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50485\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1532 - accuracy: 0.9423 - val_loss: 1.3147 - val_accuracy: 0.6932\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50485\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.1892 - accuracy: 0.9369 - val_loss: 0.6110 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50485\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1203 - accuracy: 0.9605 - val_loss: 0.7360 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50485\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 1.2262 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.50485\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1011 - accuracy: 0.9662 - val_loss: 0.7729 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.50485\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0846 - accuracy: 0.9824 - val_loss: 1.2324 - val_accuracy: 0.6705\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.50485\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0905 - accuracy: 0.9778 - val_loss: 0.6716 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.50485\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1081 - accuracy: 0.9690 - val_loss: 1.2162 - val_accuracy: 0.7045\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.50485\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1277 - accuracy: 0.9523 - val_loss: 0.7395 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.50485\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1067 - accuracy: 0.9601 - val_loss: 0.6362 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50485\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0807 - accuracy: 0.9738 - val_loss: 0.9268 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.50485\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0815 - accuracy: 0.9802 - val_loss: 0.5095 - val_accuracy: 0.8295\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50485\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0695 - accuracy: 0.9776 - val_loss: 0.4031 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.50485 to 0.40310, saving model to convolution_models_n_mfcc0050-val-loss-0032.ckpt\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0739 - accuracy: 0.9785 - val_loss: 0.5108 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.40310\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0702 - accuracy: 0.9869 - val_loss: 0.7750 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.40310\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0476 - accuracy: 0.9902 - val_loss: 0.7239 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.40310\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 0.6508 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.40310\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0528 - accuracy: 0.9894 - val_loss: 0.7912 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.40310\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0423 - accuracy: 0.9913 - val_loss: 0.5777 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.40310\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 0.4462 - val_accuracy: 0.8409\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.40310\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.4994 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.40310\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0299 - accuracy: 0.9965 - val_loss: 0.6974 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.40310\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0380 - accuracy: 0.9867 - val_loss: 0.7223 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.40310\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0253 - accuracy: 0.9978 - val_loss: 0.6362 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.40310\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0290 - accuracy: 0.9941 - val_loss: 1.2319 - val_accuracy: 0.7045\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40310\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0171 - accuracy: 0.9990 - val_loss: 0.6258 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40310\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0171 - accuracy: 0.9989 - val_loss: 0.5567 - val_accuracy: 0.8295\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40310\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0957 - accuracy: 0.9729 - val_loss: 0.6705 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40310\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 0.5814 - val_accuracy: 0.8295\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.40310\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0399 - accuracy: 0.9888 - val_loss: 0.6515 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.40310\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0249 - accuracy: 0.9982 - val_loss: 0.6576 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.40310\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0186 - accuracy: 0.9986 - val_loss: 0.6359 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.40310\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.7936 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.40310\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0145 - accuracy: 0.9986 - val_loss: 0.7573 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.40310\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.40310\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 0.5620 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.40310\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0211 - accuracy: 0.9958 - val_loss: 0.8673 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.40310\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.40310\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9243 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.40310\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.40310\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.8474 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.40310\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.7265 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.40310\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.7217 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.40310\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 1.0772 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.40310\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.9796 - val_accuracy: 0.6932\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.40310\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.40310\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.8459 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.40310\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.40310\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.7747 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.40310\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.7518 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.40310\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.40310\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.7460 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.40310\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.6686 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.40310\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8797 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.40310\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.40310\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.7386\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.40310\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.40310\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 1.0195 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.40310\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.40310\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.40310\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 1.0803 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.40310\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.40310\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8295\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.40310\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.40310\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.40310\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.40310\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.40310\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.40310\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8797 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.40310\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.40310\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.40310\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.40310\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8262 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.40310\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.40310\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7392 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.40310\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.40310\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.40310\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.40310\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.40310\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.40310\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9332 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.40310\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), \n",
    "                    batch_size=32, epochs=100, callbacks=[checkpoint_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0766 - accuracy: 0.7727\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with best val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbc8c112a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir_loss)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5841 - accuracy: 0.7841\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
